{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:05:09.052559Z",
     "start_time": "2024-03-27T18:05:06.992812Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from EDA_script import *\n",
    "# # Set options\n",
    "# pd.options.display.max_rows = 999\n",
    "# pd.options.display.max_columns = 999\n",
    "\n",
    "# train_x_raw = pd.read_csv(\"../01-Data/X_train.csv\", low_memory = True, index_col=0)\n",
    "# train_y_raw = pd.read_csv(\"../01-Data/y_train.csv\", low_memory = True, index_col=0)\n",
    "# test_x_raw = pd.read_csv(\"../01-Data/X_test.csv\", low_memory=True, index_col=0)\n",
    "\n",
    "# df_train = pd.DataFrame(train_x_raw)\n",
    "# df_test = pd.DataFrame(test_x_raw)\n",
    "# df_y = pd.DataFrame(train_y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92646daeb6719b84",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Simple Model Run\n",
    "##  xgBoost model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fbfcd048b55d241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:05:10.537531Z",
     "start_time": "2024-03-27T18:05:09.758625Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "label_mapping = {-1: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
    "df_y = df_y.replace(label_mapping)\n",
    "\n",
    "dtrain = xgb.DMatrix(df_train, label=df_y, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(df_test, enable_categorical=True)\n",
    "\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.01,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 5,\n",
    "    'eval_metric': 'mlogloss',\n",
    "}\n",
    "\n",
    "num_boost_round = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c354c",
   "metadata": {},
   "source": [
    "## Xgboost Model GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c65d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Assume df_train, df_test, and df_y are already defined and preprocessed\n",
    "# as per your setup\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1],\n",
    "}\n",
    "\n",
    "# Instantiate the XGBClassifier (note: use objective 'multi:softprob' for multi-class)\n",
    "xgb_model = XGBClassifier(objective='multi:softprob', num_class=5, eval_metric='mlogloss', use_label_encoder=False)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_log_loss', n_jobs=-1, cv=3, verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV object to find the best parameters\n",
    "grid_search.fit(df_train, df_y)\n",
    "\n",
    "# Best parameter set found\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Best score\n",
    "print(\"Best score (neg_log_loss): \", grid_search.best_score_)\n",
    "\n",
    "# You can also use the best estimator directly to make predictions\n",
    "# best_estimator = grid_search.best_estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73377ae83e283639",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6d6fdecf41fb2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:06:42.022458Z",
     "start_time": "2024-03-27T18:05:10.540713Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.526709</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>1.529876</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.456720</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>1.462868</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.396577</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>1.405702</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.344042</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>1.356013</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.297831</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>1.312425</td>\n",
       "      <td>0.001586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.256703</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>1.273919</td>\n",
       "      <td>0.001772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.219840</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>1.239523</td>\n",
       "      <td>0.001951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.186644</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>1.208749</td>\n",
       "      <td>0.002059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.156575</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>1.181099</td>\n",
       "      <td>0.002152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.129472</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>1.156434</td>\n",
       "      <td>0.002227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.104769</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>1.134278</td>\n",
       "      <td>0.002380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.082039</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>1.113862</td>\n",
       "      <td>0.002467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.061250</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>1.095507</td>\n",
       "      <td>0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.042169</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>1.078747</td>\n",
       "      <td>0.002543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.024410</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>1.063410</td>\n",
       "      <td>0.002554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.008045</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>1.049327</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.992868</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>1.036585</td>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.978664</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>1.024757</td>\n",
       "      <td>0.002785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.965228</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>1.013660</td>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.952924</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>1.003687</td>\n",
       "      <td>0.002869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.941186</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.994368</td>\n",
       "      <td>0.002961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.930123</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.985661</td>\n",
       "      <td>0.002997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.919868</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.977858</td>\n",
       "      <td>0.003057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.910067</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.970384</td>\n",
       "      <td>0.003116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.900915</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.003286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.892159</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.957204</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.883887</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.003369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.875978</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.945557</td>\n",
       "      <td>0.003286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.868493</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.940425</td>\n",
       "      <td>0.003349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.861295</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.935671</td>\n",
       "      <td>0.003401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.854459</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.931138</td>\n",
       "      <td>0.003490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.847938</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.927006</td>\n",
       "      <td>0.003603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.841606</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.923010</td>\n",
       "      <td>0.003728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.835641</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.919304</td>\n",
       "      <td>0.003741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.829843</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.915886</td>\n",
       "      <td>0.003758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.824325</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.912650</td>\n",
       "      <td>0.003776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.818955</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.909608</td>\n",
       "      <td>0.003744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.813879</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.906757</td>\n",
       "      <td>0.003776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.808832</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.904071</td>\n",
       "      <td>0.003804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.804126</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.901539</td>\n",
       "      <td>0.003882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.799446</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.899011</td>\n",
       "      <td>0.003919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.794924</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.896638</td>\n",
       "      <td>0.003919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.790546</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.894590</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.786209</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.892496</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.781946</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.890567</td>\n",
       "      <td>0.003974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.777918</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.888807</td>\n",
       "      <td>0.003995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.773876</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.886927</td>\n",
       "      <td>0.004083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.770027</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.885291</td>\n",
       "      <td>0.004056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.766203</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.883732</td>\n",
       "      <td>0.004137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.762460</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.882184</td>\n",
       "      <td>0.004202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-mlogloss-mean  train-mlogloss-std  test-mlogloss-mean  \\\n",
       "0              1.526709            0.000460            1.529876   \n",
       "1              1.456720            0.000567            1.462868   \n",
       "2              1.396577            0.000750            1.405702   \n",
       "3              1.344042            0.000861            1.356013   \n",
       "4              1.297831            0.001038            1.312425   \n",
       "5              1.256703            0.000913            1.273919   \n",
       "6              1.219840            0.000974            1.239523   \n",
       "7              1.186644            0.001114            1.208749   \n",
       "8              1.156575            0.001162            1.181099   \n",
       "9              1.129472            0.001152            1.156434   \n",
       "10             1.104769            0.001201            1.134278   \n",
       "11             1.082039            0.001179            1.113862   \n",
       "12             1.061250            0.001324            1.095507   \n",
       "13             1.042169            0.001386            1.078747   \n",
       "14             1.024410            0.001507            1.063410   \n",
       "15             1.008045            0.001542            1.049327   \n",
       "16             0.992868            0.001462            1.036585   \n",
       "17             0.978664            0.001529            1.024757   \n",
       "18             0.965228            0.001599            1.013660   \n",
       "19             0.952924            0.001627            1.003687   \n",
       "20             0.941186            0.001627            0.994368   \n",
       "21             0.930123            0.001628            0.985661   \n",
       "22             0.919868            0.001727            0.977858   \n",
       "23             0.910067            0.001682            0.970384   \n",
       "24             0.900915            0.001708            0.963544   \n",
       "25             0.892159            0.001617            0.957204   \n",
       "26             0.883887            0.001616            0.951210   \n",
       "27             0.875978            0.001636            0.945557   \n",
       "28             0.868493            0.001623            0.940425   \n",
       "29             0.861295            0.001656            0.935671   \n",
       "30             0.854459            0.001576            0.931138   \n",
       "31             0.847938            0.001569            0.927006   \n",
       "32             0.841606            0.001608            0.923010   \n",
       "33             0.835641            0.001522            0.919304   \n",
       "34             0.829843            0.001502            0.915886   \n",
       "35             0.824325            0.001505            0.912650   \n",
       "36             0.818955            0.001537            0.909608   \n",
       "37             0.813879            0.001522            0.906757   \n",
       "38             0.808832            0.001596            0.904071   \n",
       "39             0.804126            0.001577            0.901539   \n",
       "40             0.799446            0.001613            0.899011   \n",
       "41             0.794924            0.001527            0.896638   \n",
       "42             0.790546            0.001467            0.894590   \n",
       "43             0.786209            0.001526            0.892496   \n",
       "44             0.781946            0.001544            0.890567   \n",
       "45             0.777918            0.001551            0.888807   \n",
       "46             0.773876            0.001460            0.886927   \n",
       "47             0.770027            0.001443            0.885291   \n",
       "48             0.766203            0.001424            0.883732   \n",
       "49             0.762460            0.001534            0.882184   \n",
       "\n",
       "    test-mlogloss-std  \n",
       "0            0.000522  \n",
       "1            0.000987  \n",
       "2            0.001105  \n",
       "3            0.001378  \n",
       "4            0.001586  \n",
       "5            0.001772  \n",
       "6            0.001951  \n",
       "7            0.002059  \n",
       "8            0.002152  \n",
       "9            0.002227  \n",
       "10           0.002380  \n",
       "11           0.002467  \n",
       "12           0.002563  \n",
       "13           0.002543  \n",
       "14           0.002554  \n",
       "15           0.002704  \n",
       "16           0.002752  \n",
       "17           0.002785  \n",
       "18           0.002857  \n",
       "19           0.002869  \n",
       "20           0.002961  \n",
       "21           0.002997  \n",
       "22           0.003057  \n",
       "23           0.003116  \n",
       "24           0.003286  \n",
       "25           0.003376  \n",
       "26           0.003369  \n",
       "27           0.003286  \n",
       "28           0.003349  \n",
       "29           0.003401  \n",
       "30           0.003490  \n",
       "31           0.003603  \n",
       "32           0.003728  \n",
       "33           0.003741  \n",
       "34           0.003758  \n",
       "35           0.003776  \n",
       "36           0.003744  \n",
       "37           0.003776  \n",
       "38           0.003804  \n",
       "39           0.003882  \n",
       "40           0.003919  \n",
       "41           0.003919  \n",
       "42           0.003998  \n",
       "43           0.004032  \n",
       "44           0.003974  \n",
       "45           0.003995  \n",
       "46           0.004083  \n",
       "47           0.004056  \n",
       "48           0.004137  \n",
       "49           0.004202  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import cv\n",
    "\n",
    "# params and num_boost_round provided above\n",
    "xgb_cv = cv(dtrain=dtrain, params=params, nfold=10,\n",
    "            num_boost_round=num_boost_round, early_stopping_rounds=10,\n",
    "            metrics=\"mlogloss\", as_pandas=True, seed=123)\n",
    "\n",
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3eff0c1cff4b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Xgboost Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e33513991df267c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:07:06.878598Z",
     "start_time": "2024-03-27T18:06:42.025685Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multiclass Logarithmic Loss: 0.7816854378245771\n",
      "Validation Multiclass Logarithmic Loss: 0.7816854274180483\n"
     ]
    }
   ],
   "source": [
    "evals_result = {}\n",
    "bst = xgb.train(params, dtrain, num_boost_round, \n",
    "                evals=[(dtrain, 'train')], evals_result=evals_result, \n",
    "                verbose_eval=False)\n",
    "print(f\"Training Multiclass Logarithmic Loss: {evals_result['train']['mlogloss'][-1]}\")\n",
    "\n",
    "y_test_probs = bst.predict(dtest)\n",
    "\n",
    "class_order = [0, 1, 2, 3, 4]\n",
    "class_mapping = {class_label: f\"Class_{class_label}\" for class_label in class_order}\n",
    "\n",
    "y_train_probs = bst.predict(dtrain)\n",
    "val_log_loss = log_loss(df_y, y_train_probs, labels=class_order)\n",
    "print(f\"Validation Multiclass Logarithmic Loss: {val_log_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527521c5801211",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate Submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ae6668498e2687f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:07:06.910218Z",
     "start_time": "2024-03-27T18:07:06.882783Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(y_test_probs, columns=class_mapping.values())\n",
    "submission_df.columns = ['no answer', 'very important', 'quite important', 'not important', 'not at all important']\n",
    "submission_df.insert(0, 'id', df_test.index)\n",
    "\n",
    "# Save the submission file\n",
    "# submission_file = ('submission.csv')\n",
    "# submission_df.to_csv(submission_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
