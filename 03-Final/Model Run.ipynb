{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T23:43:16.064482Z",
     "start_time": "2024-03-27T23:43:16.051481Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from EDA_script import *\n",
<<<<<<< HEAD
    "#from EDA_script2 import *\n",
=======
>>>>>>> jeonghan
    "# # Set options\n",
    "# pd.options.display.max_rows = 999\n",
    "# pd.options.display.max_columns = 999\n",
    "\n",
    "# train_x_raw = pd.read_csv(\"../01-Data/X_train.csv\", low_memory = True, index_col=0)\n",
    "# train_y_raw = pd.read_csv(\"../01-Data/y_train.csv\", low_memory = True, index_col=0)\n",
    "# test_x_raw = pd.read_csv(\"../01-Data/X_test.csv\", low_memory=True, index_col=0)\n",
    "\n",
    "# df_train = pd.DataFrame(train_x_raw)\n",
    "# df_test = pd.DataFrame(test_x_raw)\n",
    "# df_y = pd.DataFrame(train_y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "25c05a8884dfda7f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add all of the preprocessing below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39710aab3026879d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Variable 1 - 146 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d335519eab176102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T23:43:16.095198Z",
     "start_time": "2024-03-27T23:43:16.081829Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# columns_to_drop = ['c_abrv', 'f46_IT', 'v72_DE', 'v73_DE', 'v74_DE', 'v75_DE', 'v76_DE', 'v77_DE', 'v78_DE', 'v79_DE']\n",
    "# df_train.drop(columns=columns_to_drop, inplace=True)\n",
    "# df_test.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef956e35e6f124",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Variable 147 - 292 Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f908a39187ffa8bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T23:43:16.110274Z",
     "start_time": "2024-03-27T23:43:16.097200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ### Function to find the targeted colname\n",
    "# def find_colname(data, target):\n",
    "#     temp = []\n",
    "#     for varname in data.columns:\n",
    "#         if varname.endswith(target):\n",
    "#             temp.append(varname)\n",
    "#     return(temp)\n",
    "\n",
    "# merge_colname = find_colname(train_x_raw, '_11c')\n",
    "# print(find_colname(train_x_raw, 'c'))\n",
    "# print(find_colname(train_x_raw, '_r'))\n",
    "\n",
    "# def merge_columns(dat, colname):\n",
    "#     for name in colname:\n",
    "#         name_org = name.replace(\"_11c\", \"\")\n",
    "#         dat.loc[dat[name_org] == -4, name_org] = dat.loc[dat[name_org] == -4, name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d251374774258cc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Variable 293 - 438 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "74a294a5eb2c211d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T23:43:16.125531Z",
     "start_time": "2024-03-27T23:43:16.116533Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## removed string type data\n",
    "# df_train.drop('v228b', inplace=True, axis=1) \n",
    "# df_test.drop('v228b', inplace=True, axis=1) \n",
    "\n",
    "# df_train.fillna({'v228b_r': -3}, inplace=True)\n",
    "# df_test.fillna({'v228b_r': -3}, inplace=True)\n",
    "\n",
    "# df_train.drop('v231b', inplace=True, axis=1) \n",
    "# df_test.drop('v231b', inplace=True, axis=1)\n",
    "\n",
    "# df_train.fillna({'v231b_r': -3}, inplace=True)\n",
    "# df_test.fillna({'v231b_r': -3}, inplace=True)\n",
    "\n",
    "# df_train.drop('v233b', inplace=True, axis=1)\n",
    "# df_test.drop('v233b', inplace=True, axis=1)\n",
    "\n",
    "# df_train.fillna({'v233b_r': -3}, inplace=True)\n",
    "# df_test.fillna({'v233b_r': -3}, inplace=True)\n",
    "\n",
    "# df_train.drop('v251b', inplace=True, axis=1)\n",
    "# df_test.drop('v251b', inplace=True, axis=1) \n",
    "\n",
    "# df_train.fillna({'v251b_r': -3}, inplace=True)\n",
    "# df_test.fillna({'v251b_r': -3}, inplace=True)\n",
    "\n",
    "# df_train.drop('f252_edulvlb_CH', inplace=True, axis=1)\n",
    "# df_test.drop('f252_edulvlb_CH', inplace=True, axis=1)\n",
    "\n",
    "# ## removed the column having 'DE'\n",
    "# df_train.drop(list(df_train.filter(regex='DE')), axis=1, inplace=True)\n",
    "# df_test.drop(list(df_test.filter(regex='DE')), axis=1, inplace=True)\n",
    "\n",
    "# ## removed the column having 'GB'\n",
    "# df_train.drop(list(df_train.filter(regex='GB')), axis=1, inplace=True)\n",
    "# df_test.drop(list(df_test.filter(regex='GB')), axis=1, inplace=True)\n",
    "\n",
    "# df_train.drop('v281a', inplace=True, axis=1)\n",
    "# df_test.drop('v281a', inplace=True, axis=1)\n",
    "\n",
    "# df_train.drop('v275b_N2', inplace=True, axis=1) \n",
    "# df_test.drop('v275b_N2', inplace=True, axis=1) \n",
    "\n",
    "# df_train.drop('v275b_N1', inplace=True, axis=1) \n",
    "# df_test.drop('v275b_N1', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
=======
>>>>>>> jeonghan
   "id": "92646daeb6719b84",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Simple Model Run\n",
    "##  xgBoost model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< HEAD
   "id": "4e587eec02fcf1e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T23:45:55.456967Z",
     "start_time": "2024-03-27T23:45:55.372698Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amyoo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\amyoo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type numpy.ndarray doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 25\u001B[0m\n\u001B[0;32m     23\u001B[0m select_X_test \u001B[38;5;241m=\u001B[39m selection\u001B[38;5;241m.\u001B[39mtransform(df_test)\n\u001B[0;32m     24\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m selection_model\u001B[38;5;241m.\u001B[39mpredict_proba(select_X_test)\n\u001B[1;32m---> 25\u001B[0m predictions \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mround\u001B[39m(value) \u001B[38;5;28;01mfor\u001B[39;00m value \u001B[38;5;129;01min\u001B[39;00m y_pred]\n\u001B[0;32m     26\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(df_y, predictions)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThresh=\u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m, n=\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m, Accuracy: \u001B[39m\u001B[38;5;132;01m%.2f\u001B[39;00m\u001B[38;5;132;01m%%\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (thresh, select_X_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], accuracy\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100.0\u001B[39m))\n",
      "Cell \u001B[1;32mIn[2], line 25\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     23\u001B[0m select_X_test \u001B[38;5;241m=\u001B[39m selection\u001B[38;5;241m.\u001B[39mtransform(df_test)\n\u001B[0;32m     24\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m selection_model\u001B[38;5;241m.\u001B[39mpredict_proba(select_X_test)\n\u001B[1;32m---> 25\u001B[0m predictions \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mround\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m value \u001B[38;5;129;01min\u001B[39;00m y_pred]\n\u001B[0;32m     26\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(df_y, predictions)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThresh=\u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m, n=\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m, Accuracy: \u001B[39m\u001B[38;5;132;01m%.2f\u001B[39;00m\u001B[38;5;132;01m%%\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (thresh, select_X_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], accuracy\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100.0\u001B[39m))\n",
      "\u001B[1;31mTypeError\u001B[0m: type numpy.ndarray doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "label_mapping = {-1: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
    "df_y = df_y.replace(label_mapping)\n",
    "\n",
    "# Assuming df_train is your training data and df_y is the target variable\n",
    "model = xgb.XGBClassifier(objective='multi:softprob', num_class=5, eval_metric='mlogloss')\n",
    "model.fit(df_train, df_y)\n",
    "\n",
    "# Select features based on weight\n",
    "thresholds = np.sort(model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(df_train)\n",
    "    \n",
    "    # train model\n",
    "    selection_model = xgb.XGBClassifier(objective='multi:softprob', num_class=5, eval_metric='mlogloss')\n",
    "    selection_model.fit(select_X_train, df_y)\n",
    "    \n",
    "    # eval model\n",
    "    select_X_test = selection.transform(df_test)\n",
    "    y_pred = selection_model.predict_proba(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(df_y, predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
=======
>>>>>>> jeonghan
   "id": "5fbfcd048b55d241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:19:29.648272Z",
     "start_time": "2024-03-27T22:19:28.872969Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "label_mapping = {-1: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
    "df_y = df_y.replace(label_mapping)\n",
    "\n",
    "dtrain = xgb.DMatrix(df_train, label=df_y, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(df_test, enable_categorical=True)\n",
    "\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.01,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 5,\n",
    "    'eval_metric': 'mlogloss',\n",
    "}\n",
    "\n",
<<<<<<< HEAD
    "num_boost_round = 700"
=======
    "num_boost_round = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c354c",
   "metadata": {},
   "source": [
    "## Xgboost Model GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c65d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Assume df_train, df_test, and df_y are already defined and preprocessed\n",
    "# as per your setup\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 1000],\n",
    "    'subsample': [1],\n",
    "    'colsample_bytree': [1],\n",
    "}\n",
    "\n",
    "# Instantiate the XGBClassifier (note: use objective 'multi:softprob' for multi-class)\n",
    "xgb_model = XGBClassifier(objective='multi:softprob', num_class=5, eval_metric='mlogloss', use_label_encoder=False)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_log_loss', n_jobs=-1, cv=3, verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV object to find the best parameters\n",
    "grid_search.fit(df_train, df_y)\n",
    "\n",
    "# Best parameter set found\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Best score\n",
    "print(\"Best score (neg_log_loss): \", grid_search.best_score_)\n",
    "\n",
    "# You can also use the best estimator directly to make predictions\n",
    "# best_estimator = grid_search.best_estimator\n"
>>>>>>> jeonghan
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73377ae83e283639",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 193,
=======
   "execution_count": null,
>>>>>>> jeonghan
   "id": "ee6d6fdecf41fb2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:19:29.663914Z",
     "start_time": "2024-03-27T22:19:29.649343Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import cv\n",
    "\n",
    "# params and num_boost_round provided above\n",
<<<<<<< HEAD
    "# xgb_cv = cv(dtrain=dtrain, params=params, nfold=5,\n",
    "#             num_boost_round=num_boost_round, early_stopping_rounds=10,\n",
    "#             metrics=\"mlogloss\", as_pandas=True, seed=123)\n",
    "# \n",
    "# xgb_cv"
=======
    "xgb_cv = cv(dtrain=dtrain, params=params, nfold=10,\n",
    "            num_boost_round=num_boost_round, early_stopping_rounds=10,\n",
    "            metrics=\"mlogloss\", as_pandas=True, seed=123)\n",
    "\n",
    "xgb_cv"
>>>>>>> jeonghan
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3eff0c1cff4b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Xgboost Training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 194,
=======
   "execution_count": null,
>>>>>>> jeonghan
   "id": "7e33513991df267c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:20:59.631379Z",
     "start_time": "2024-03-27T22:19:29.665406Z"
    },
    "collapsed": false
   },
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multiclass Logarithmic Loss: 0.7253980584744519\n",
      "Validation Multiclass Logarithmic Loss: 0.7253980481467168\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> jeonghan
   "source": [
    "evals_result = {}\n",
    "bst = xgb.train(params, dtrain, num_boost_round, \n",
    "                evals=[(dtrain, 'train')], evals_result=evals_result, \n",
    "                verbose_eval=False)\n",
    "print(f\"Training Multiclass Logarithmic Loss: {evals_result['train']['mlogloss'][-1]}\")\n",
    "\n",
    "y_test_probs = bst.predict(dtest)\n",
    "\n",
    "class_order = [0, 1, 2, 3, 4]\n",
    "class_mapping = {class_label: f\"Class_{class_label}\" for class_label in class_order}\n",
    "\n",
    "y_train_probs = bst.predict(dtrain)\n",
    "val_log_loss = log_loss(df_y, y_train_probs, labels=class_order)\n",
    "print(f\"Validation Multiclass Logarithmic Loss: {val_log_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527521c5801211",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate Submission csv"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 196,
=======
   "execution_count": null,
>>>>>>> jeonghan
   "id": "5ae6668498e2687f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T22:21:18.609273Z",
     "start_time": "2024-03-27T22:21:18.536011Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(y_test_probs, columns=class_mapping.values())\n",
    "submission_df.columns = ['no answer', 'very important', 'quite important', 'not important', 'not at all important']\n",
    "submission_df.insert(0, 'id', df_test.index)\n",
    "\n",
    "# Save the submission file\n",
    "#submission_file = ('amy3_submission.csv')\n",
    "#submission_df.to_csv(submission_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc762fbac597443",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.7"
=======
   "version": "3.10.12"
>>>>>>> jeonghan
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
