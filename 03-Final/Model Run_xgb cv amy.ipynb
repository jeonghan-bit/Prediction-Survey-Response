{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T15:52:46.437270Z",
     "start_time": "2024-03-29T15:52:39.077910Z"
    }
   },
   "outputs": [],
   "source": [
    "from EDA_script2 import *\n",
    "\n",
    "# train_x_raw = pd.read_csv(\"../01-Data/X_train.csv\", low_memory = True, index_col=0)\n",
    "# train_y_raw = pd.read_csv(\"../01-Data/y_train.csv\", low_memory = True, index_col=0)\n",
    "# test_x_raw = pd.read_csv(\"../01-Data/X_test.csv\", low_memory=True, index_col=0)\n",
    "\n",
    "# df_train = pd.DataFrame(train_x_raw)\n",
    "# df_test = pd.DataFrame(test_x_raw)\n",
    "# df_y = pd.DataFrame(train_y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92646daeb6719b84",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Simple Model Run\n",
    "##  xgBoost model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bddb8136d0bf8985",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T18:09:21.012823Z",
     "start_time": "2024-03-28T18:09:20.677745Z"
    }
   },
   "outputs": [],
   "source": [
    "# # one-hot encoding\n",
    "# \n",
    "# # Apply get_dummies to the entire DataFrame, automatically encoding all categorical columns\n",
    "# df_train_encoded = pd.get_dummies(df_train)\n",
    "# df_test_encoded = pd.get_dummies(df_test)\n",
    "# \n",
    "# # To ensure the training and test sets have the same columns after encoding, you might need to align them\n",
    "# df_train_encoded, df_test_encoded = df_train_encoded.align(df_test_encoded, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "label_mapping = {-1: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
    "df_y = df_y.replace(label_mapping)\n",
    "\n",
    "dtrain = xgb.DMatrix(df_train, label=df_y, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(df_test, enable_categorical=True)\n",
    "\n",
    "params = {\n",
    "    'max_depth': 6,  \n",
    "    'colsample_bytree': 0.7,  # Reduced\n",
    "    'gamma': 0.4,  # Slightly increased\n",
    "    'subsample': 0.6,  # Reduced\n",
    "    'eta': 0.005,  # Reduced\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 5,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'lambda': 2,  # Increased L2 regularization\n",
    "    'alpha': 0.2,  # Increased L1 regularization\n",
    "    'min_child_weight': 3  # Added to control overfitting\n",
    "    # 'n_estimators': 2000, # Uncomment and adjust as necessary\n",
    "}\n",
    "\n",
    "\n",
    "num_boost_round = 1000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:52:52.849742Z",
     "start_time": "2024-03-29T15:52:51.465669Z"
    }
   },
   "id": "5fbfcd048b55d241",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "73377ae83e283639",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1e13af07068a7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import cv\n",
    "\n",
    "# params and num_boost_round provided above\n",
    "# xgb_cv = cv(dtrain=dtrain, params=params, nfold=5,\n",
    "#             num_boost_round=num_boost_round, early_stopping_rounds=10,\n",
    "#             metrics=\"mlogloss\", as_pandas=True, seed=123)\n",
    "# \n",
    "# xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb6c86c5bcb84258"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |    eta    |   gamma   | max_depth | min_ch... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001B[0m1        \u001B[0m | \u001B[0m-0.8725  \u001B[0m | \u001B[0m0.5247   \u001B[0m | \u001B[0m0.2857   \u001B[0m | \u001B[0m0.732    \u001B[0m | \u001B[0m7.191    \u001B[0m | \u001B[0m1.78     \u001B[0m | \u001B[0m0.156    \u001B[0m | \u001B[0m1.232    \u001B[0m | \u001B[0m0.8197   \u001B[0m |\n",
      "| \u001B[0m2        \u001B[0m | \u001B[0m-0.9     \u001B[0m | \u001B[0m0.6607   \u001B[0m | \u001B[0m0.2153   \u001B[0m | \u001B[0m0.02058  \u001B[0m | \u001B[0m9.789    \u001B[0m | \u001B[0m5.162    \u001B[0m | \u001B[0m0.2123   \u001B[0m | \u001B[0m1.727    \u001B[0m | \u001B[0m0.41     \u001B[0m |\n",
      "| \u001B[95m3        \u001B[0m | \u001B[95m-0.852   \u001B[0m | \u001B[95m0.4825   \u001B[0m | \u001B[95m0.1622   \u001B[0m | \u001B[95m0.4319   \u001B[0m | \u001B[95m5.039    \u001B[0m | \u001B[95m4.059    \u001B[0m | \u001B[95m0.1395   \u001B[0m | \u001B[95m2.169    \u001B[0m | \u001B[95m0.5198   \u001B[0m |\n",
      "| \u001B[0m4        \u001B[0m | \u001B[0m-0.8714  \u001B[0m | \u001B[0m0.5736   \u001B[0m | \u001B[0m0.2377   \u001B[0m | \u001B[0m0.1997   \u001B[0m | \u001B[0m6.6      \u001B[0m | \u001B[0m3.962    \u001B[0m | \u001B[0m0.04645  \u001B[0m | \u001B[0m3.43     \u001B[0m | \u001B[0m0.4023   \u001B[0m |\n",
      "| \u001B[0m5        \u001B[0m | \u001B[0m-0.8882  \u001B[0m | \u001B[0m0.339    \u001B[0m | \u001B[0m0.2852   \u001B[0m | \u001B[0m0.9656   \u001B[0m | \u001B[0m8.659    \u001B[0m | \u001B[0m2.523    \u001B[0m | \u001B[0m0.09767  \u001B[0m | \u001B[0m3.737    \u001B[0m | \u001B[0m0.5641   \u001B[0m |\n",
      "| \u001B[0m6        \u001B[0m | \u001B[0m-1.214   \u001B[0m | \u001B[0m0.9      \u001B[0m | \u001B[0m0.01     \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m3.0      \u001B[0m | \u001B[0m2.402    \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m2.019    \u001B[0m | \u001B[0m0.3      \u001B[0m |\n",
      "| \u001B[0m7        \u001B[0m | \u001B[0m-0.8543  \u001B[0m | \u001B[0m0.4762   \u001B[0m | \u001B[0m0.2289   \u001B[0m | \u001B[0m0.5406   \u001B[0m | \u001B[0m6.249    \u001B[0m | \u001B[0m3.377    \u001B[0m | \u001B[0m0.1394   \u001B[0m | \u001B[0m2.117    \u001B[0m | \u001B[0m0.6163   \u001B[0m |\n",
      "| \u001B[0m8        \u001B[0m | \u001B[0m-0.8561  \u001B[0m | \u001B[0m0.3      \u001B[0m | \u001B[0m0.3      \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m6.122    \u001B[0m | \u001B[0m5.948    \u001B[0m | \u001B[0m0.3878   \u001B[0m | \u001B[0m1.479    \u001B[0m | \u001B[0m0.9      \u001B[0m |\n",
      "| \u001B[95m9        \u001B[0m | \u001B[95m-0.8483  \u001B[0m | \u001B[95m0.3      \u001B[0m | \u001B[95m0.3      \u001B[0m | \u001B[95m1.0      \u001B[0m | \u001B[95m4.875    \u001B[0m | \u001B[95m6.0      \u001B[0m | \u001B[95m1.0      \u001B[0m | \u001B[95m4.213    \u001B[0m | \u001B[95m0.9      \u001B[0m |\n",
      "| \u001B[0m10       \u001B[0m | \u001B[0m-1.154   \u001B[0m | \u001B[0m0.9      \u001B[0m | \u001B[0m0.01     \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m8.165    \u001B[0m | \u001B[0m6.0      \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m5.0      \u001B[0m | \u001B[0m0.9      \u001B[0m |\n",
      "| \u001B[0m11       \u001B[0m | \u001B[0m-0.8548  \u001B[0m | \u001B[0m0.3      \u001B[0m | \u001B[0m0.3      \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m3.685    \u001B[0m | \u001B[0m6.0      \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m2.064    \u001B[0m | \u001B[0m0.9      \u001B[0m |\n",
      "| \u001B[0m12       \u001B[0m | \u001B[0m-1.153   \u001B[0m | \u001B[0m0.9      \u001B[0m | \u001B[0m0.01     \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m10.0     \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m0.3      \u001B[0m |\n",
      "| \u001B[0m13       \u001B[0m | \u001B[0m-0.8542  \u001B[0m | \u001B[0m0.3      \u001B[0m | \u001B[0m0.3      \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m3.0      \u001B[0m | \u001B[0m6.0      \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m4.824    \u001B[0m | \u001B[0m0.9      \u001B[0m |\n",
      "| \u001B[0m14       \u001B[0m | \u001B[0m-0.8542  \u001B[0m | \u001B[0m0.3      \u001B[0m | \u001B[0m0.3      \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m6.559    \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m5.0      \u001B[0m | \u001B[0m0.9      \u001B[0m |\n",
      "| \u001B[0m15       \u001B[0m | \u001B[0m-1.193   \u001B[0m | \u001B[0m0.9      \u001B[0m | \u001B[0m0.01     \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m4.783    \u001B[0m | \u001B[0m6.0      \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m2.911    \u001B[0m | \u001B[0m0.3      \u001B[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_train, df_y are already defined and preprocessed\n",
    "\n",
    "def xgb_cv_score(max_depth, gamma, colsample_bytree, subsample, eta, reg_lambda, reg_alpha, min_child_weight):\n",
    "    \"\"\"\n",
    "    This function computes the cross-validated log loss using Stratified K-Fold\n",
    "    for the given hyperparameter settings.\n",
    "    \"\"\"\n",
    "    # Parameters that the optimizer can explore\n",
    "    params = {\n",
    "        'max_depth': int(max_depth),\n",
    "        'gamma': gamma,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'subsample': subsample,\n",
    "        'eta': eta,\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 5,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'lambda': reg_lambda,\n",
    "        'alpha': reg_alpha,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'verbosity': 0,  # Quiet mode\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    # Convert to DMatrix for efficiency\n",
    "    dtrain = xgb.DMatrix(df_train, label=df_y)\n",
    "\n",
    "    # Stratified K-Fold Cross Validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    log_loss_scores = []\n",
    "\n",
    "    for train_index, test_index in skf.split(df_train, df_y):\n",
    "        xgb_train = xgb.DMatrix(df_train.iloc[train_index], label=df_y.iloc[train_index])\n",
    "        xgb_test = xgb.DMatrix(df_train.iloc[test_index], label=df_y.iloc[test_index])\n",
    "\n",
    "        # Train the model\n",
    "        model = xgb.train(params, xgb_train, num_boost_round=100)\n",
    "\n",
    "        # Predict & evaluate\n",
    "        preds = model.predict(xgb_test)\n",
    "        log_loss_score = log_loss(df_y.iloc[test_index], preds, labels=list(range(5)))\n",
    "        log_loss_scores.append(log_loss_score)\n",
    "\n",
    "    # Return the negative mean log loss\n",
    "    return -np.mean(log_loss_scores)\n",
    "\n",
    "# Define the parameter bounds\n",
    "pbounds = {\n",
    "    'max_depth': (3, 10),\n",
    "    'gamma': (0, 1),\n",
    "    'colsample_bytree': (0.3, 0.9),\n",
    "    'subsample': (0.3, 0.9),\n",
    "    'eta': (0.01, 0.3),\n",
    "    'reg_lambda': (1, 5),\n",
    "    'reg_alpha': (0, 1),\n",
    "    'min_child_weight': (1, 6),\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(f=xgb_cv_score, pbounds=pbounds, random_state=42, verbose=2)\n",
    "\n",
    "# Optimize\n",
    "optimizer.maximize(init_points=5, n_iter=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:07:37.694131Z",
     "start_time": "2024-03-29T15:53:10.523316Z"
    }
   },
   "id": "ee6d6fdecf41fb2a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.45452\tval-mlogloss:1.45574\n",
      "[1]\ttrain-mlogloss:1.34216\tval-mlogloss:1.34513\n",
      "[2]\ttrain-mlogloss:1.24903\tval-mlogloss:1.25491\n",
      "[3]\ttrain-mlogloss:1.17460\tval-mlogloss:1.18179\n",
      "[4]\ttrain-mlogloss:1.11779\tval-mlogloss:1.12587\n",
      "[5]\ttrain-mlogloss:1.08120\tval-mlogloss:1.09083\n",
      "[6]\ttrain-mlogloss:1.04510\tval-mlogloss:1.05597\n",
      "[7]\ttrain-mlogloss:1.01296\tval-mlogloss:1.02575\n",
      "[8]\ttrain-mlogloss:0.98879\tval-mlogloss:1.00312\n",
      "[9]\ttrain-mlogloss:0.96552\tval-mlogloss:0.98203\n",
      "[10]\ttrain-mlogloss:0.95327\tval-mlogloss:0.97142\n",
      "[11]\ttrain-mlogloss:0.93943\tval-mlogloss:0.95908\n",
      "[12]\ttrain-mlogloss:0.92721\tval-mlogloss:0.94860\n",
      "[13]\ttrain-mlogloss:0.91389\tval-mlogloss:0.93703\n",
      "[14]\ttrain-mlogloss:0.90490\tval-mlogloss:0.92978\n",
      "[15]\ttrain-mlogloss:0.89559\tval-mlogloss:0.92180\n",
      "[16]\ttrain-mlogloss:0.88847\tval-mlogloss:0.91621\n",
      "[17]\ttrain-mlogloss:0.88148\tval-mlogloss:0.91080\n",
      "[18]\ttrain-mlogloss:0.87510\tval-mlogloss:0.90559\n",
      "[19]\ttrain-mlogloss:0.86918\tval-mlogloss:0.90067\n",
      "[20]\ttrain-mlogloss:0.86285\tval-mlogloss:0.89538\n",
      "[21]\ttrain-mlogloss:0.85798\tval-mlogloss:0.89236\n",
      "[22]\ttrain-mlogloss:0.85330\tval-mlogloss:0.88928\n",
      "[23]\ttrain-mlogloss:0.84966\tval-mlogloss:0.88746\n",
      "[24]\ttrain-mlogloss:0.84611\tval-mlogloss:0.88582\n",
      "[25]\ttrain-mlogloss:0.84180\tval-mlogloss:0.88318\n",
      "[26]\ttrain-mlogloss:0.83866\tval-mlogloss:0.88180\n",
      "[27]\ttrain-mlogloss:0.83532\tval-mlogloss:0.87975\n",
      "[28]\ttrain-mlogloss:0.83148\tval-mlogloss:0.87775\n",
      "[29]\ttrain-mlogloss:0.82808\tval-mlogloss:0.87583\n",
      "[30]\ttrain-mlogloss:0.82433\tval-mlogloss:0.87362\n",
      "[31]\ttrain-mlogloss:0.82056\tval-mlogloss:0.87168\n",
      "[32]\ttrain-mlogloss:0.81769\tval-mlogloss:0.87082\n",
      "[33]\ttrain-mlogloss:0.81501\tval-mlogloss:0.87006\n",
      "[34]\ttrain-mlogloss:0.81238\tval-mlogloss:0.86927\n",
      "[35]\ttrain-mlogloss:0.80966\tval-mlogloss:0.86865\n",
      "[36]\ttrain-mlogloss:0.80691\tval-mlogloss:0.86775\n",
      "[37]\ttrain-mlogloss:0.80468\tval-mlogloss:0.86692\n",
      "[38]\ttrain-mlogloss:0.80208\tval-mlogloss:0.86624\n",
      "[39]\ttrain-mlogloss:0.79934\tval-mlogloss:0.86500\n",
      "[40]\ttrain-mlogloss:0.79681\tval-mlogloss:0.86414\n",
      "[41]\ttrain-mlogloss:0.79469\tval-mlogloss:0.86366\n",
      "[42]\ttrain-mlogloss:0.79217\tval-mlogloss:0.86267\n",
      "[43]\ttrain-mlogloss:0.78968\tval-mlogloss:0.86179\n",
      "[44]\ttrain-mlogloss:0.78727\tval-mlogloss:0.86082\n",
      "[45]\ttrain-mlogloss:0.78512\tval-mlogloss:0.86054\n",
      "[46]\ttrain-mlogloss:0.78306\tval-mlogloss:0.86020\n",
      "[47]\ttrain-mlogloss:0.78075\tval-mlogloss:0.85991\n",
      "[48]\ttrain-mlogloss:0.77902\tval-mlogloss:0.85957\n",
      "[49]\ttrain-mlogloss:0.77700\tval-mlogloss:0.85901\n",
      "[50]\ttrain-mlogloss:0.77477\tval-mlogloss:0.85837\n",
      "[51]\ttrain-mlogloss:0.77274\tval-mlogloss:0.85814\n",
      "[52]\ttrain-mlogloss:0.77068\tval-mlogloss:0.85779\n",
      "[53]\ttrain-mlogloss:0.76884\tval-mlogloss:0.85763\n",
      "[54]\ttrain-mlogloss:0.76683\tval-mlogloss:0.85749\n",
      "[55]\ttrain-mlogloss:0.76512\tval-mlogloss:0.85719\n",
      "[56]\ttrain-mlogloss:0.76303\tval-mlogloss:0.85682\n",
      "[57]\ttrain-mlogloss:0.76101\tval-mlogloss:0.85649\n",
      "[58]\ttrain-mlogloss:0.75895\tval-mlogloss:0.85601\n",
      "[59]\ttrain-mlogloss:0.75715\tval-mlogloss:0.85568\n",
      "[60]\ttrain-mlogloss:0.75547\tval-mlogloss:0.85538\n",
      "[61]\ttrain-mlogloss:0.75349\tval-mlogloss:0.85522\n",
      "[62]\ttrain-mlogloss:0.75201\tval-mlogloss:0.85520\n",
      "[63]\ttrain-mlogloss:0.75012\tval-mlogloss:0.85515\n",
      "[64]\ttrain-mlogloss:0.74869\tval-mlogloss:0.85505\n",
      "[65]\ttrain-mlogloss:0.74699\tval-mlogloss:0.85468\n",
      "[66]\ttrain-mlogloss:0.74520\tval-mlogloss:0.85462\n",
      "[67]\ttrain-mlogloss:0.74349\tval-mlogloss:0.85453\n",
      "[68]\ttrain-mlogloss:0.74171\tval-mlogloss:0.85436\n",
      "[69]\ttrain-mlogloss:0.73983\tval-mlogloss:0.85404\n",
      "[70]\ttrain-mlogloss:0.73828\tval-mlogloss:0.85389\n",
      "[71]\ttrain-mlogloss:0.73659\tval-mlogloss:0.85388\n",
      "[72]\ttrain-mlogloss:0.73508\tval-mlogloss:0.85383\n",
      "[73]\ttrain-mlogloss:0.73347\tval-mlogloss:0.85372\n",
      "[74]\ttrain-mlogloss:0.73179\tval-mlogloss:0.85357\n",
      "[75]\ttrain-mlogloss:0.73039\tval-mlogloss:0.85363\n",
      "[76]\ttrain-mlogloss:0.72890\tval-mlogloss:0.85321\n",
      "[77]\ttrain-mlogloss:0.72769\tval-mlogloss:0.85289\n",
      "[78]\ttrain-mlogloss:0.72621\tval-mlogloss:0.85281\n",
      "[79]\ttrain-mlogloss:0.72469\tval-mlogloss:0.85291\n",
      "[80]\ttrain-mlogloss:0.72316\tval-mlogloss:0.85254\n",
      "[81]\ttrain-mlogloss:0.72178\tval-mlogloss:0.85234\n",
      "[82]\ttrain-mlogloss:0.72045\tval-mlogloss:0.85220\n",
      "[83]\ttrain-mlogloss:0.71904\tval-mlogloss:0.85215\n",
      "[84]\ttrain-mlogloss:0.71747\tval-mlogloss:0.85201\n",
      "[85]\ttrain-mlogloss:0.71624\tval-mlogloss:0.85177\n",
      "[86]\ttrain-mlogloss:0.71488\tval-mlogloss:0.85172\n",
      "[87]\ttrain-mlogloss:0.71341\tval-mlogloss:0.85182\n",
      "[88]\ttrain-mlogloss:0.71198\tval-mlogloss:0.85167\n",
      "[89]\ttrain-mlogloss:0.71053\tval-mlogloss:0.85170\n",
      "[90]\ttrain-mlogloss:0.70894\tval-mlogloss:0.85163\n",
      "[91]\ttrain-mlogloss:0.70746\tval-mlogloss:0.85176\n",
      "[92]\ttrain-mlogloss:0.70587\tval-mlogloss:0.85195\n",
      "[93]\ttrain-mlogloss:0.70429\tval-mlogloss:0.85191\n",
      "[94]\ttrain-mlogloss:0.70305\tval-mlogloss:0.85181\n",
      "[95]\ttrain-mlogloss:0.70146\tval-mlogloss:0.85173\n",
      "[96]\ttrain-mlogloss:0.70005\tval-mlogloss:0.85177\n",
      "[97]\ttrain-mlogloss:0.69858\tval-mlogloss:0.85169\n",
      "[98]\ttrain-mlogloss:0.69744\tval-mlogloss:0.85166\n",
      "[99]\ttrain-mlogloss:0.69622\tval-mlogloss:0.85171\n",
      "[100]\ttrain-mlogloss:0.69472\tval-mlogloss:0.85160\n",
      "[101]\ttrain-mlogloss:0.69345\tval-mlogloss:0.85157\n",
      "[102]\ttrain-mlogloss:0.69199\tval-mlogloss:0.85170\n",
      "[103]\ttrain-mlogloss:0.69093\tval-mlogloss:0.85179\n",
      "[104]\ttrain-mlogloss:0.68968\tval-mlogloss:0.85169\n",
      "[105]\ttrain-mlogloss:0.68837\tval-mlogloss:0.85190\n",
      "[106]\ttrain-mlogloss:0.68693\tval-mlogloss:0.85191\n",
      "[107]\ttrain-mlogloss:0.68572\tval-mlogloss:0.85191\n",
      "[108]\ttrain-mlogloss:0.68444\tval-mlogloss:0.85177\n",
      "[109]\ttrain-mlogloss:0.68332\tval-mlogloss:0.85155\n",
      "[110]\ttrain-mlogloss:0.68186\tval-mlogloss:0.85154\n",
      "[111]\ttrain-mlogloss:0.68058\tval-mlogloss:0.85164\n",
      "[112]\ttrain-mlogloss:0.67920\tval-mlogloss:0.85146\n",
      "[113]\ttrain-mlogloss:0.67784\tval-mlogloss:0.85147\n",
      "[114]\ttrain-mlogloss:0.67669\tval-mlogloss:0.85155\n",
      "[115]\ttrain-mlogloss:0.67543\tval-mlogloss:0.85147\n",
      "[116]\ttrain-mlogloss:0.67448\tval-mlogloss:0.85148\n",
      "[117]\ttrain-mlogloss:0.67316\tval-mlogloss:0.85125\n",
      "[118]\ttrain-mlogloss:0.67177\tval-mlogloss:0.85132\n",
      "[119]\ttrain-mlogloss:0.67105\tval-mlogloss:0.85152\n",
      "[120]\ttrain-mlogloss:0.66996\tval-mlogloss:0.85180\n",
      "[121]\ttrain-mlogloss:0.66869\tval-mlogloss:0.85162\n",
      "[122]\ttrain-mlogloss:0.66748\tval-mlogloss:0.85168\n",
      "[123]\ttrain-mlogloss:0.66631\tval-mlogloss:0.85163\n",
      "[124]\ttrain-mlogloss:0.66518\tval-mlogloss:0.85146\n",
      "[125]\ttrain-mlogloss:0.66395\tval-mlogloss:0.85152\n",
      "[126]\ttrain-mlogloss:0.66272\tval-mlogloss:0.85150\n",
      "[127]\ttrain-mlogloss:0.66165\tval-mlogloss:0.85164\n",
      "Training Multiclass Logarithmic Loss: 0.661646788128003\n",
      "Validation Multiclass Logarithmic Loss: 0.8516384310195119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming df_train is your features and df_y is your labels\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train, df_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create DMatrix for training and validation\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, enable_categorical=True)\n",
    "\n",
    "best_params = {\n",
    "    'max_depth': int(optimizer.max['params']['max_depth']),\n",
    "    'gamma': optimizer.max['params']['gamma'],\n",
    "    'colsample_bytree': optimizer.max['params']['colsample_bytree'],\n",
    "    'subsample': optimizer.max['params']['subsample'],\n",
    "    'eta': optimizer.max['params']['eta'],\n",
    "    'lambda': optimizer.max['params']['reg_lambda'],\n",
    "    'alpha': optimizer.max['params']['reg_alpha'],\n",
    "    'min_child_weight': optimizer.max['params']['min_child_weight'],\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 5,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'verbosity': 0,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Container for evaluation results\n",
    "evals_result = {}\n",
    "\n",
    "# Train the model\n",
    "bst = xgb.train(best_params, dtrain, num_boost_round,\n",
    "                    evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "                    evals_result=evals_result,\n",
    "                    early_stopping_rounds=10,\n",
    "                    verbose_eval=True)\n",
    "\n",
    "# Retrieve the last evaluation metric for both train and val sets\n",
    "train_last_eval = evals_result['train']['mlogloss'][-1]\n",
    "val_last_eval = evals_result['val']['mlogloss'][-1]\n",
    "\n",
    "print(f\"Training Multiclass Logarithmic Loss: {train_last_eval}\")\n",
    "print(f\"Validation Multiclass Logarithmic Loss: {val_last_eval}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:16:46.710269Z",
     "start_time": "2024-03-29T16:16:38.057372Z"
    }
   },
   "id": "9039f880957f11d3",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "fcf3eff0c1cff4b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## xgboost train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedfdcf8bb9d5e92",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evals_result = {}\n",
    "# bst = xgb.train(params, dtrain, num_boost_round, \n",
    "#                 evals=[(dtrain, 'train')], evals_result=evals_result, \n",
    "#                 verbose_eval=False)\n",
    "# print(f\"Training Multiclass Logarithmic Loss: {evals_result['train']['mlogloss'][-1]}\")\n",
    "# \n",
    "# y_test_probs = bst.predict(dtest)\n",
    "# \n",
    "# class_order = [0, 1, 2, 3, 4]\n",
    "# class_mapping = {class_label: f\"Class_{class_label}\" for class_label in class_order}\n",
    "# \n",
    "# y_train_probs = bst.predict(dtrain)\n",
    "# val_log_loss = log_loss(df_y, y_train_probs, labels=class_order)\n",
    "# print(f\"Validation Multiclass Logarithmic Loss: {val_log_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527521c5801211",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate Submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ae6668498e2687f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T18:12:52.554951Z",
     "start_time": "2024-03-28T18:12:52.465357Z"
    }
   },
   "outputs": [],
   "source": [
    "# submission_df = pd.DataFrame(y_test_probs, columns=class_mapping.values())\n",
    "# submission_df.columns = ['no answer', 'very important', 'quite important', 'not important', 'not at all important']\n",
    "# submission_df.insert(0, 'id', df_test.index)\n",
    "# \n",
    "# # Save the submission file\n",
    "# submission_file = ('test_submission.csv')\n",
    "# submission_df.to_csv(submission_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
